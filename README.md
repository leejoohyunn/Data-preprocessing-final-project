# Data-preprocessing-final-project
# 하이퍼파라미터 튜닝
## 1.1 하이퍼파라미터의 역할과 중요성
### 1.1.1 하이퍼파라미터와 모델 매개변수의 차이 (Hyperparameter vs. Parameter)
- 파라미터(매개변수): 모델이 데이터에서 규칙을 학습하는 데 사용되는 변수이며 훈련 과정에서 알고리즘에 의해 업데이트 됩니다. 파라미터에 대해 최적의 값을 설정하지 않지만, 데이터에서 자체 값을 학습합니다. 파라미터의 최적 값이 찾아지면 모델은 훈련을 마칩니다.
- 하이퍼파라미터(초매개변수): 모델 훈련을 제어하는 변수입니다. 따라서 하이퍼파라미터는 파라미터의 값을 제어할 수 있습니다. 즉, 파라미터의 최적 값은 사용하는 하이퍼파라미터의 값에 따라 달라집니다. 파라미터와는 달리, 하이퍼파라미터는 데이터에서 값을 학습하지 않고, 모델을 훈련하기 전에 수동으로 지정해야 합니다. 일단 지정되면 하이퍼파라미터 값은 모델 훈련 중에 고정됩니다. 
(https://medium.com/data-science-365/parameters-vs-hyperparameters-what-is-the-difference-5f40e16e2e82)
(https://velog.io/@emseoyk/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D)

| 하이퍼파리미터                             | 파라미터                                          |
|------------------------------------------:|--------------------------------------------------:|
|학습 과정에 반영되는 값, 학습 시작 전 미리 조정| 데이터로부터 학습 또는 예측되는 값, 모델 내부에서 결정|
|ex) 학습률, 손실 함수, 배치 사이즈            |선형회귀 계수, 가중치, 편향, 평균, 표준편차           |
|직접 조정 가능                               |직접 조정 불가능                                    |

## 1.2 하이퍼파라미터의 종류
1. **학습률(Learning Rate)**: 모델이 한 번의 학습 단계에서 얼마나 많이 학습하는지를 조절합니다. 너무 작은 학습률은 수렴을 느리게 할 수 있고, 너무 큰 학습률은 발산의 위험을 가지고 있습니다.
2. **배치 크기(batch size)**: 모델이 각 학습 단계에서 처리하는 데이터 샘플의 개수를 나타냅니다. 적절한 배치 크기를 선택하는 것은 모델의 효율성에 영향을 미칩니다.
3. **에포크 수(Number of Epochs)**: 전체 데이터셋을 한 번 훈련하는 것을 1 에포크라고 합니다. 에포크 수는 전체 데이터셋을 몇 번 반복해서 훈련할지를 결정합니다.
4. **가중치 감소(Weight Decay)**: 과적합을 방지하기 위해 가중치 감소를 사용합니다. 이는 가중치 값이 너무 크지 않도록 제한하는 역할을 합니다.
5. **드롭아웃 비율(Dropout Rate)**:드롭아웃은 학습 중에 무작위로 일부 뉴런을 제외하여 모델의 일반화 성능을 향상시키는 데 사용됩니다. 드롭아웃 비율은 제외될 뉴런의 비율을 나타냅니다.
6. **활성화 함수(Activation Function)**:모델의 각 레이어에서 사용되는 활성화 함수를 결정합니다. 대표적으로는 ReLU, Sigmoid, tanh 등이 있습니다.
7. **최적화 알고리즘(Optimizer)**:모델의 가중치를 업데이트하는 데 사용되는 최적화 알고리즘을 선택합니다. 대표적으로는 SGD, Adam, RMSprop 등이 있습니다.
8. **은닉층 수와 뉴런 수**:신경망의 구조를 결정하는 하이퍼파라미터로, 은닉층의 수와 각 은닉층의 뉴런 수를 조절합니다.
9. **합성곱 신경망(CNN)에서의 커널 크기와 스트라이드**:이미지 분류와 같은 작업에서 사용되는 CNN에서는 커널 크기와 스트라이드를 조절하여 특징을 추출하는 방식을 결정합니다.
10. **랜덤 시드(Random Seed)**:랜덤 초기화를 사용하는 경우, 랜덤 시드는 동일한 조건에서 실험을 재현하기 위해 사용됩니다.

## 1.3 튜닝 방법 소개
## 1.4 실제 적용 사례
